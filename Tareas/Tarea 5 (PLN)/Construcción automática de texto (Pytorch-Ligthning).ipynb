{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHkYFOFNvqi-"
      },
      "source": [
        "# **Construcción automática de texto (Pytorch-Ligthning)**\n",
        "Andrey Duvan Rincon Torres\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "bfIgLe48v3xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyyaml==5.4.1"
      ],
      "metadata": {
        "id": "4_fmt58fOP7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plotly_express"
      ],
      "metadata": {
        "id": "hCyy-hRuOUBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "id": "8uF3ELUi5Ag1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 333,
      "metadata": {
        "id": "2SAgacGzvqjB"
      },
      "outputs": [],
      "source": [
        "# Librerias Nesesarias\n",
        "import torch\n",
        "import pandas as pd\n",
        "import plotly.express as plx\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from torch import nn\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torchmetrics.functional import accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchmetrics.functional import accuracy\n",
        "CELoss = nn.CrossEntropyLoss()\n",
        "# Para el texto\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre tratamiento de los datos**"
      ],
      "metadata": {
        "id": "qh0stdFDuiH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar los datos\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")"
      ],
      "metadata": {
        "id": "hVGtel0quhgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear estructura de datos\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "# crea predictores y etiqueta\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "kPzwy96yu6aY"
      },
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.utils import to_categorical\n",
        "# label = to_categorical(label, num_classes=total_words)"
      ],
      "metadata": {
        "id": "9LKaVv93nmjb"
      },
      "execution_count": 336,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtPrf9w1vqjD"
      },
      "source": [
        "## **Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 378,
      "metadata": {
        "id": "zhGdzUbEvqjD"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  # creamos la estructura de la red\n",
        "  def __init__(self):\n",
        "      super(Model,self).__init__()\n",
        "      # Embeding de las palabras\n",
        "      self.embedding = nn.Embedding(total_words, 100)\n",
        "      # Red Bidireccional\n",
        "      self.lstm_1 = nn.LSTM(100, 150, 1, batch_first=True, dropout = 0.2 , bidirectional = True)\n",
        "      # red LSTM\n",
        "      self.lstm_2 = nn.LSTM(300*(max_sequence_len - 1),100,1, batch_first=True)\n",
        "      # red perceptron\n",
        "      self.linear_1 = nn.Linear(100,1605)\n",
        "      self.linear_2 = nn.Linear(1605,total_words)\n",
        "      self.relu = nn.ReLU()\n",
        "      self.sofmax = nn.Softmax()\n",
        "  # definimos el comportamiento de las capas\n",
        "  def forward(self, x):\n",
        "      batch_size, channelsn = x.size()\n",
        "      x = self.embedding(x)\n",
        "      # layer LSTM bidirectional\n",
        "      out, (h_n, c_n) = self.lstm_1(x)\n",
        "      # layer LSTM\n",
        "      out, (h_n, c_n) = self.lstm_2(out.reshape((batch_size,-1)))\n",
        "      # capa de salida\n",
        "      out = self.relu(self.linear_1(out))\n",
        "      out = self.sofmax(self.linear_2(out))\n",
        "      return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len"
      ],
      "metadata": {
        "id": "d8DjQmXJsLct",
        "outputId": "12a5932f-9520-424b-fb22-f76a1690e550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 367,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 367
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjuZpFfIvqjE"
      },
      "source": [
        "## **Datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 387,
      "metadata": {
        "id": "P5ks3sNGvqjF"
      },
      "outputs": [],
      "source": [
        "# Clase de los datos\n",
        "class DataModule(pl.LightningDataModule):\n",
        "  # Definimos un tamaño de lote en la calse\n",
        "  def __init__(self, batch_size = 32):\n",
        "      super(DataModule,self).__init__()\n",
        "      self.batch_size = batch_size\n",
        "  # Definimos el tratamiento de los datos\n",
        "  def setup(self, stage=None):\n",
        "    x, y = predictors, label\n",
        "    # Conjunto de validacion\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.1, random_state = 0,shuffle=True)\n",
        "    # Transformar en tensores\n",
        "    self.train_dataset = TensorDataset(torch.tensor(x_train.astype(np.int32)),torch.tensor(y_train.astype(np.int32)))\n",
        "    self.val_dataset = TensorDataset(torch.tensor(x_val.astype(np.int32)),torch.tensor(y_val.astype(np.int32)))\n",
        "  # Iterable de entrenamiento\n",
        "  def train_dataloader(self):\n",
        "      return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
        "  # Iterable de validacion\n",
        "  def val_dataloader(self):\n",
        "      return DataLoader(self.val_dataset, batch_size=self.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4NBS67avqjG"
      },
      "source": [
        "## **Entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 412,
      "metadata": {
        "id": "pZ5hav7dvqjG"
      },
      "outputs": [],
      "source": [
        "class Train(pl.LightningModule):\n",
        "    # creamos la estructura de la red\n",
        "    def __init__(self,model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "   # Paso de entrenamiento\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss,acc = self._shared_eval_step(batch, batch_idx)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "        return loss\n",
        "    # Paso de validacion\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss,acc = self._shared_eval_step(batch, batch_idx)\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "        return loss\n",
        "    # Funcion para evaluar el modelo y la perdida\n",
        "    def _shared_eval_step(self,batch,batch_idx):\n",
        "        x, y  = batch\n",
        "        y_hat = self.model(x)\n",
        "        loss = CELoss(y_hat, y.type(torch.LongTensor))\n",
        "        acc = accuracy(y_hat, y.type(torch.LongTensor))\n",
        "        return loss, acc\n",
        "    # Configuracion del optimizador\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "input = torch.randn(10, 5, requires_grad=True)\n",
        "target = torch.empty(10, dtype=torch.long).random_(5)\n",
        "output = loss(input, target)"
      ],
      "metadata": {
        "id": "ldOm5D1Bugi4"
      },
      "execution_count": 413,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-5vDOLSvqjH"
      },
      "source": [
        "##  Ajustar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0gQZdFIvqjH"
      },
      "outputs": [],
      "source": [
        "data_module = DataModule() # Ejecutamos modulo de datos\n",
        "torch.manual_seed(0)\n",
        "model = Model() # Ejecutamos modelo\n",
        "trainer = pl.Trainer(max_epochs=100, progress_bar_refresh_rate=20) # Lamamos el entrenador\n",
        "task = Train(model)\n",
        "trainer.fit(task,data_module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tablero de resultados\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "metadata": {
        "id": "m-MKlW038Puk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generacion de texto**"
      ],
      "metadata": {
        "id": "v3MyAH9o7uww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = \"Who are you, so too cruel?\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "    predicted = model.forward(torch.tensor(token_list.astype(np.float32))).detach().numpy().transpose()[0]\n",
        "    output_word = \"\"\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "        if index == predicted:\n",
        "            output_word = word\n",
        "            break\n",
        "    seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ],
      "metadata": {
        "id": "6dHlDubE7tT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "94e7570899995adebab4ebab5cd3752e227f734c99b4f5f3f0d280f8bef09b63"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('IA')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Gasolina.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}