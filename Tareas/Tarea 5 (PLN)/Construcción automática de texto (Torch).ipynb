{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHkYFOFNvqi-"
      },
      "source": [
        "# **Construcción automática de texto (Pytorch-Ligthning)**\n",
        "Andrey Duvan Rincon Torres\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "bfIgLe48v3xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyyaml==5.4.1"
      ],
      "metadata": {
        "id": "4_fmt58fOP7g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install plotly_express"
      ],
      "metadata": {
        "id": "hCyy-hRuOUBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchmetrics"
      ],
      "metadata": {
        "id": "8uF3ELUi5Ag1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2SAgacGzvqjB"
      },
      "outputs": [],
      "source": [
        "# Librerias Nesesarias\n",
        "import torch\n",
        "import pandas as pd\n",
        "import plotly.express as plx\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from torch import nn\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "from torchmetrics.functional import accuracy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchmetrics.functional import accuracy\n",
        "CELoss = nn.CrossEntropyLoss()\n",
        "# Para el texto\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Pre tratamiento de los datos**"
      ],
      "metadata": {
        "id": "qh0stdFDuiH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar los datos\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sonnets.txt \\\n",
        "    -O /tmp/sonnets.txt\n",
        "data = open('/tmp/sonnets.txt').read()\n",
        "\n",
        "corpus = data.lower().split(\"\\n\")"
      ],
      "metadata": {
        "id": "hVGtel0quhgj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear estructura de datos\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "# crea predictores y etiqueta\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "kPzwy96yu6aY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Codificar One Hot variables categoricas\n",
        "encoder_lab = OneHotEncoder()\n",
        "encoder_lab.fit(label.reshape(-1, 1))\n",
        "label = encoder_lab.transform(label.reshape(-1, 1)).toarray()"
      ],
      "metadata": {
        "id": "6ODUdJj9vqor"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtPrf9w1vqjD"
      },
      "source": [
        "## **Modelo**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zhGdzUbEvqjD"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "  # creamos la estructura de la red\n",
        "  def __init__(self):\n",
        "      super(Model,self).__init__()\n",
        "      # Embeding de las palabras\n",
        "      embedding = nn.Embedding(total_words, 100)\n",
        "      # Red Bidireccional\n",
        "      self.lstm_1 = nn.LSTM(100, 150, 1, batch_first=True, dropout = 0.2 , bidirectional = True)\n",
        "      # red LSTM\n",
        "      self.lstm_2 = nn.LSTM(150,100,1, batch_first=True)\n",
        "      # red perceptron\n",
        "      self.linear_1 = nn.Linear(100,1605)\n",
        "      self.linear_2 = nn.Linear(1605,total_words)\n",
        "  # definimos el comportamiento de las capas\n",
        "  def forward(self, x):\n",
        "      batch_size, channels, width = x.size()\n",
        "      # layer LSTM bidirectional\n",
        "      out, (h_n, c_n) = self.lstm_1(x)\n",
        "      # layer LSTM\n",
        "      out, (h_n, c_n) = self.lstm_2(out)\n",
        "      # capa de salida\n",
        "      out = nn.ReLU(self.linear_1(out))\n",
        "      out = nn.Softmax(self.linear_2(out))\n",
        "      return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjuZpFfIvqjE"
      },
      "source": [
        "## **Datos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5ks3sNGvqjF"
      },
      "outputs": [],
      "source": [
        "# Clase de los datos\n",
        "class DataModule(pl.LightningDataModule):\n",
        "  # Definimos un tamaño de lote en la calse\n",
        "  def __init__(self, batch_size = 32):\n",
        "      super(DataModule,self).__init__()\n",
        "      self.batch_size = batch_size\n",
        "  # Definimos el tratamiento de los datos\n",
        "  def setup(self, stage=None):\n",
        "    x, y = predictors, label\n",
        "    # Conjunto de validacion\n",
        "    x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.1, random_state = 0,shuffle=True)\n",
        "    # Transformar en tensores\n",
        "    self.train_dataset = TensorDataset(torch.tensor(x_train.astype(np.float32)),torch.tensor(y_train.astype(np.float32)))\n",
        "    self.val_dataset = TensorDataset(torch.tensor(x_val.astype(np.float32)),torch.tensor(y_val.astype(np.float32)))\n",
        "  # Iterable de entrenamiento\n",
        "  def train_dataloader(self):\n",
        "      return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
        "  # Iterable de validacion\n",
        "  def val_dataloader(self):\n",
        "      return DataLoader(self.val_dataset, batch_size=self.batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4NBS67avqjG"
      },
      "source": [
        "## **Entrenamiento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZ5hav7dvqjG"
      },
      "outputs": [],
      "source": [
        "class Train(pl.LightningModule):\n",
        "    # creamos la estructura de la red\n",
        "    def __init__(self,model):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "   # Paso de entrenamiento\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        loss,acc = self._shared_eval_step(batch, batch_idx)\n",
        "        self.log(\"train_loss\", loss, prog_bar=True)\n",
        "        self.log(\"train_acc\", acc, prog_bar=True)\n",
        "        return loss\n",
        "    # Paso de validacion\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        loss,acc = self._shared_eval_step(batch, batch_idx)\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        self.log(\"val_acc\", acc, prog_bar=True)\n",
        "        return loss\n",
        "    # Funcion para evaluar el modelo y la perdida\n",
        "    def _shared_eval_step(self,batch,batch_idx):\n",
        "        x, y  = batch\n",
        "        y_hat = self.model(x)\n",
        "        loss = BCELoss(y_hat, y.unsqueeze(1))\n",
        "        acc = self.accuracy(y_hat.softmax(-1), y.int().unsqueeze(1))\n",
        "        return loss, acc\n",
        "    # Configuracion del optimizador\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.model.parameters())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-5vDOLSvqjH"
      },
      "source": [
        "##  Ajustar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0gQZdFIvqjH"
      },
      "outputs": [],
      "source": [
        "data_module = DataModule() # Ejecutamos modulo de datos\n",
        "torch.manual_seed(0)\n",
        "model = Model() # Ejecutamos modelo\n",
        "trainer = pl.Trainer(max_epochs=100, progress_bar_refresh_rate=20) # Lamamos el entrenador\n",
        "task = Train(model)\n",
        "trainer.fit(task,data_module)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tablero de resultados\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "metadata": {
        "id": "m-MKlW038Puk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Generacion de texto**"
      ],
      "metadata": {
        "id": "v3MyAH9o7uww"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6dHlDubE7tT2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "94e7570899995adebab4ebab5cd3752e227f734c99b4f5f3f0d280f8bef09b63"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('IA')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "Gasolina.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}